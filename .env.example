# LLM Provider Configuration
# Choose one: ollama, groq, cerebras, google_genai
LLM_PROVIDER=ollama

# ========================================
# Ollama Configuration (Recommended: Local, Free, No Limits)
# ========================================
OLLAMA_MODEL=llama3.2
OLLAMA_BASE_URL=http://localhost:11434
# Install: Run ./setup_ollama.sh or see FREE_LLM_SETUP.md

# ========================================
# Groq Configuration (Online, Free, High Limits)
# ========================================
# Get API key from: https://console.groq.com/
# GROQ_API_KEY=gsk_your_api_key_here
# GROQ_MODEL=llama-3.1-8b-instant
# Limits: 30 RPM, 14,400 RPD (much higher than Gemini!)

# ========================================
# Cerebras Configuration (Online, Free)
# ========================================
# Get API key from: https://inference.cerebras.ai/
# CEREBRAS_API_KEY=your_api_key_here
# CEREBRAS_MODEL=llama3.1-8b

# ========================================
# Google Gemini Configuration (Original, Low Free Limits)
# ========================================
# Get API key from: https://aistudio.google.com/app/apikey
# GOOGLE_API_KEY=your_google_api_key_here
# GEMINI_MODEL=gemini-2.0-flash
# Limits: 15 RPM, 1500 RPD (easily exceeded)

# ========================================
# Tool Configuration
# ========================================
TAVILY_API_KEY=your_tavily_api_key_here

# ========================================
# LangSmith (Optional Tracing)
# ========================================
LANGSMITH_PROJECT=new-agent
ANTHROPIC_API_KEY=your_anthropic_api_key_here
