# å¿«é€Ÿå¼€å§‹æŒ‡å—

## ðŸš€ æœ€å¿« 5 åˆ†é’Ÿå¼€å§‹è¯„ä¼°

### æ­¥éª¤ 1: é€‰æ‹© LLM æä¾›å•†

ä½ æœ‰ 3 ä¸ªå…è´¹é€‰é¡¹ï¼š

#### é€‰é¡¹ A: Ollamaï¼ˆæŽ¨è - æœ¬åœ°è¿è¡Œï¼Œæ— é™åˆ¶ï¼‰

```bash
# 1. å®‰è£… Ollama (macOS)
brew install ollama

# 2. å¯åŠ¨æœåŠ¡
ollama serve &

# 3. ä¸‹è½½æ¨¡åž‹
ollama pull llama3.2

# 4. é…ç½®çŽ¯å¢ƒå˜é‡
cat >> .env << 'EOF'
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama3.2
OLLAMA_BASE_URL=http://localhost:11434
EOF
```

#### é€‰é¡¹ B: Groqï¼ˆåœ¨çº¿ï¼Œé«˜é…é¢ï¼‰

```bash
# 1. æ³¨å†ŒèŽ·å– API key: https://console.groq.com/
# 2. é…ç½®çŽ¯å¢ƒå˜é‡
cat >> .env << 'EOF'
LLM_PROVIDER=groq
GROQ_API_KEY=gsk_your_api_key_here
GROQ_MODEL=llama-3.1-8b-instant
EOF
```

#### é€‰é¡¹ C: ç»§ç»­ä½¿ç”¨ Geminiï¼ˆæœ‰é™åˆ¶ï¼‰

```bash
# ä¿æŒçŽ°æœ‰çš„ GOOGLE_API_KEY
cat >> .env << 'EOF'
LLM_PROVIDER=google_genai
GEMINI_MODEL=gemini-2.0-flash
EOF
```

---

### æ­¥éª¤ 2: æµ‹è¯•é…ç½®

```bash
# æµ‹è¯• LLM é…ç½®æ˜¯å¦æ­£ç¡®
python src/llm_config.py
```

ä½ åº”è¯¥çœ‹åˆ°ï¼š
```
âœ… Ollama: llama3.2 at http://localhost:11434
æˆ–
âœ… Using Groq: llama-3.1-8b-instant
```

---

### æ­¥éª¤ 3: è¿è¡Œè¯„ä¼°

```bash
# å¿«é€Ÿæµ‹è¯•ï¼ˆ2 ä¸ª patternsï¼Œ4 ä¸ªä»»åŠ¡ï¼‰
python run_evaluation.py --mode quick

# å®Œæ•´è¯„ä¼°ï¼ˆ4 ä¸ª patternsï¼Œ16 ä¸ªä»»åŠ¡ï¼‰
python run_evaluation.py --mode full

# å•ç±»åˆ«æµ‹è¯•
python run_evaluation.py --mode category --category baseline
```

**å»¶è¿Ÿè®¾ç½®ï¼š**
- Ollama: `--delay 0`ï¼ˆæ— é™åˆ¶ï¼ï¼‰
- Groq: `--delay 2.0`ï¼ˆé«˜é…é¢ï¼‰
- Gemini: `--delay 10.0`ï¼ˆä½Žé…é¢ï¼‰

---

## ðŸ“Š æŸ¥çœ‹ç»“æžœ

è¯„ä¼°å®ŒæˆåŽï¼ŒæŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šï¼š

```bash
# JSON è¯¦ç»†ç»“æžœ
cat reports/evaluation_results.json

# Markdown æŠ¥å‘Š
cat reports/evaluation_report.md

# CSV å¯¹æ¯”è¡¨
cat reports/comparison_table.csv

# å¯è§†åŒ–å›¾è¡¨
open reports/figures/
```

---

## â“ æ•…éšœæŽ’é™¤

### é—®é¢˜ 1: "Cannot connect to Ollama"

```bash
# ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ
ollama serve &

# æµ‹è¯•è¿žæŽ¥
curl http://localhost:11434/api/tags
```

### é—®é¢˜ 2: "API key not found"

```bash
# æ£€æŸ¥ .env æ–‡ä»¶
cat .env

# ç¡®ä¿åŒ…å«æ­£ç¡®çš„é…ç½®
# å¯¹äºŽ Groq:
grep GROQ_API_KEY .env

# å¯¹äºŽ Gemini:
grep GOOGLE_API_KEY .env
```

### é—®é¢˜ 3: "429 Rate Limit"

```bash
# å¢žåŠ å»¶è¿Ÿ
python run_evaluation.py --mode quick --delay 10.0

# æˆ–åˆ‡æ¢åˆ° Ollamaï¼ˆæ— é™åˆ¶ï¼‰
```

---

## ðŸŽ¯ æŽ¨èé…ç½®

### å¼€å‘å’Œè°ƒè¯•
```bash
# ä½¿ç”¨ Ollamaï¼Œæ— å»¶è¿Ÿ
LLM_PROVIDER=ollama
python run_evaluation.py --mode quick --delay 0
```

### æ­£å¼è¯„ä¼°
```bash
# ä½¿ç”¨ Groq æˆ– Ollama
LLM_PROVIDER=groq  # æˆ– ollama
python run_evaluation.py --mode full --delay 2.0
```

---

## ðŸ“š æ›´å¤šæ–‡æ¡£

- å…è´¹ LLM è®¾ç½®è¯¦ç»†æŒ‡å—: `FREE_LLM_SETUP.md`
- é€ŸçŽ‡é™åˆ¶è§£å†³æ–¹æ¡ˆ: `RATE_LIMIT_GUIDE.md`
- è¯„ä¼°æ¡†æž¶æ–‡æ¡£: `src/evaluation/README.md`

---

## âœ… æ£€æŸ¥æ¸…å•

- [ ] é€‰æ‹©å¹¶é…ç½® LLM provider
- [ ] æµ‹è¯•é…ç½® (`python src/llm_config.py`)
- [ ] è¿è¡Œå¿«é€Ÿæµ‹è¯•éªŒè¯
- [ ] è¿è¡Œå®Œæ•´è¯„ä¼°
- [ ] æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Š

å®ŒæˆåŽä½ å°±èƒ½å¾—åˆ° 4 ä¸ª patterns çš„å®Œæ•´å¯¹æ¯”åˆ†æžï¼ðŸŽ‰
