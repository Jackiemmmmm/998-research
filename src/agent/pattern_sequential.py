"""Sequential Pattern Demo - é¡ºåºå¤„ç†æ¨¡å¼.

é€‚ç”¨åœºæ™¯ï¼šå¤šæ­¥éª¤æ ‡å‡†åŒ–æµç¨‹
ç‰¹ç‚¹ï¼šè§„åˆ’â†’æ‰§è¡Œâ†’å®¡æŸ¥çš„æµæ°´çº¿ï¼Œé«˜å»¶è¿Ÿä½†ç»“æœå¯é .
"""

from typing import Annotated

from langchain_core.messages import AIMessage
from langgraph.graph import END, START, StateGraph
from langgraph.graph.message import add_messages
from typing_extensions import TypedDict

from src.llm_config import get_llm
from src.tool import tools


class SequentialState(TypedDict):
    """State for sequential pattern with planning, execution, and review stages."""

    messages: Annotated[list, add_messages]
    stage: str
    plan: str
    execution_result: str
    evaluation_mode: bool  # If True, output clean results without verbose formatting


# åˆå§‹åŒ–æ¨¡å‹ - ä½¿ç”¨é…ç½®çš„ LLM
llm = get_llm()


# è§„åˆ’èŠ‚ç‚¹
def planning_node(state: SequentialState):
    """ç¬¬ä¸€é˜¶æ®µï¼šä»»åŠ¡è§„åˆ’."""
    planning_llm = llm.bind_tools([])  # è§„åˆ’é˜¶æ®µä¸ä½¿ç”¨å·¥å…·

    # è·å–ç”¨æˆ·çš„åŸå§‹æŸ¥è¯¢
    user_query = state["messages"][-1].content if state["messages"] else "No query"

    # æ„å»ºæ­£ç¡®çš„æ¶ˆæ¯æ ¼å¼
    planning_messages = [
        {
            "role": "user",
            "content": f"""You are in the PLANNING stage of a sequential processing pattern.

Original query: {user_query}

Your task: Create a detailed step-by-step plan to address this query.

Characteristics of Sequential Pattern:
- Break down complex tasks into clear sequential steps
- Plan before executing
- Ensure comprehensive coverage

Please provide a numbered plan (1, 2, 3, etc.) for handling this query.
Format: "PLAN: [your detailed plan here]"
""",
        }
    ]

    response = planning_llm.invoke(planning_messages)
    plan = response.content

    return {
        "messages": state["messages"]
        + [AIMessage(content=f"ğŸ“‹ Planning Stage: {plan}")],
        "stage": "execution",
        "plan": plan,
        "execution_result": "",
        "evaluation_mode": state.get("evaluation_mode", False),
    }


# æ‰§è¡ŒèŠ‚ç‚¹
def execution_node(state: SequentialState):
    """ç¬¬äºŒé˜¶æ®µï¼šè®¡åˆ’æ‰§è¡Œ."""
    # ç»‘å®šå·¥å…·ï¼Œè®©executioné˜¶æ®µå¯ä»¥ä½¿ç”¨å·¥å…·
    execution_llm = llm.bind_tools(tools)

    # è·å–åŸå§‹ç”¨æˆ·æŸ¥è¯¢
    original_query = (
        state["messages"][0].content if state["messages"] else "No original query"
    )

    # æ„å»ºæ‰§è¡Œæ¶ˆæ¯ - è®©LLMå®Œæˆæ‰€æœ‰å¿…è¦çš„å·¥å…·è°ƒç”¨
    execution_messages = [
        {
            "role": "user", 
            "content": f"""You are executing a plan to answer this question: "{original_query}"

Plan to follow: {state.get('plan', 'No plan available')}

Execute this plan completely. Use tools when needed for information you cannot provide directly. Once you have all the information needed to answer the user's question comprehensively, provide a complete response without using any more tools.

Your goal is to provide a final, complete answer to the user's question.""",
        }
    ]

    try:
        response = execution_llm.invoke(execution_messages)

        # ç›´æ¥è¿”å›LLMå“åº”ï¼Œè®©tools_conditionå†³å®šè·¯ç”±
        execution_content = (
            response.content.strip() if response.content else "No response generated"
        )

        return {
            "messages": state["messages"] + [response],
            "stage": "review",
            "plan": state.get("plan", ""),
            "execution_result": execution_content,
            "evaluation_mode": state.get("evaluation_mode", False),
        }
    except Exception as e:
        error_message = f"Execution failed with error: {str(e)}"
        return {
            "messages": state["messages"]
            + [AIMessage(content=f"âš¡ Execution Stage: {error_message}")],
            "stage": "review",
            "plan": state.get("plan", ""),
            "execution_result": error_message,
            "evaluation_mode": state.get("evaluation_mode", False),
        }


# å®¡æŸ¥èŠ‚ç‚¹
def review_node(state: SequentialState):
    """ç¬¬ä¸‰é˜¶æ®µï¼šç»“æœå®¡æŸ¥."""
    review_llm = llm.bind_tools([])  # å®¡æŸ¥é˜¶æ®µä¸ä½¿ç”¨å·¥å…·

    # è·å–åŸå§‹ç”¨æˆ·æŸ¥è¯¢
    original_query = (
        state["messages"][0].content if state["messages"] else "No original query"
    )

    # Check if in evaluation mode
    evaluation_mode = state.get("evaluation_mode", False)

    # Adjust prompt based on evaluation mode
    if evaluation_mode:
        # Evaluation mode: output only the concise answer
        review_prompt = f"""You are in the REVIEW stage of a sequential processing pattern.

Original User Query: {original_query}
Plan Created: {state.get('plan', 'No plan')}
Execution Result: {state.get('execution_result', 'No execution result')}

Your task: Provide ONLY the direct answer to the user's query. Be extremely concise.

IMPORTANT:
- Output ONLY the answer itself, nothing more
- For calculations: output only the number (e.g., "408", not "The result is 408")
- For facts: output only the fact (e.g., "Paris", not "The capital is Paris")
- For dates: output only the date in requested format
- For JSON: output only the JSON object
- NO explanations, NO prefixes, NO formatting

Provide only the answer:"""
    else:
        # Demo mode: comprehensive user-friendly response
        review_prompt = f"""You are in the REVIEW stage of a sequential processing pattern.

Original User Query: {original_query}
Plan Created: {state.get('plan', 'No plan')}
Execution Result: {state.get('execution_result', 'No execution result')}

Your task: Provide a final, comprehensive answer to the user's original query.

Guidelines:
- Synthesize the planning and execution results into a cohesive response
- Address the user's original question directly and completely
- Include key insights from the systematic analysis
- Present the information in a clear, user-friendly format
- Don't mention internal stages - just provide the final answer

Please provide the final answer that directly addresses the user's query."""

    # æ„å»ºæ­£ç¡®çš„æ¶ˆæ¯æ ¼å¼
    review_messages = [{"role": "user", "content": review_prompt}]

    response = review_llm.invoke(review_messages)

    # æä¾›æœ€ç»ˆçš„æ•´åˆç­”æ¡ˆï¼Œä½¿ç”¨AIMessageç¡®ä¿æ­£ç¡®æ˜¾ç¤º
    final_message = AIMessage(content=response.content)

    return {
        "messages": state["messages"] + [final_message],
        "stage": "completed",
        "plan": state.get("plan", ""),
        "execution_result": state.get("execution_result", ""),
        "evaluation_mode": state.get("evaluation_mode", False),
    }


# è·¯ç”±å‡½æ•°å·²ç®€åŒ–ï¼Œç›´æ¥åœ¨å›¾æ„å»ºä¸­ä½¿ç”¨è¾¹è¿æ¥

# æ„å»ºå›¾
builder = StateGraph(SequentialState)

# æ·»åŠ èŠ‚ç‚¹
builder.add_node("planning", planning_node)
builder.add_node("execution", execution_node)
builder.add_node("review", review_node)

# ä¸éœ€è¦å•ç‹¬çš„toolsèŠ‚ç‚¹ï¼Œexecutionè‡ªå·±å¤„ç†å·¥å…·è°ƒç”¨

# é…ç½®è¾¹ - äº¤ç»™LLMè‡ªè¡Œåˆ¤æ–­
builder.add_edge(START, "planning")
builder.add_edge("planning", "execution")
# æœ€ç®€å•çš„é…ç½®ï¼šexecutionå®Œæˆåç›´æ¥åˆ°review
builder.add_edge("execution", "review")
builder.add_edge("review", END)

# ç¼–è¯‘å›¾
graph_pattern_sequential = builder.compile()
